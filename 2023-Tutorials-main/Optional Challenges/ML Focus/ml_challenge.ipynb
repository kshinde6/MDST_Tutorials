{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test, optimize, and analyze the performance of a classification model using a methodology of your choice for the randomly generated moons dataset.\n",
    "\n",
    "You are not being evaluated for the performance of your model. Instead, we are interested in whether you can implement a simple but rigorous ML workflow.\n",
    "\n",
    "Show all of your work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are free to use any package you deem fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, Y = make_moons(random_state=42, n_samples=(50, 450), noise=0.25)\n",
    "\n",
    "#Data preparation: Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Selection: Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "#Model Training\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Model Evaluation: Predict on the test set\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "#Confusion Matrix\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Import necessary libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.datasets import make_moons\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Generate the moons dataset\n",
    "# X, Y = make_moons(random_state=42, n_samples=(50, 450), noise=0.25)\n",
    "\n",
    "# # Step 1: Data Preparation\n",
    "# # Split the data into training (80%) and testing (20%) sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Step 2: Model Selection\n",
    "# # Let's start with a simple Logistic Regression model\n",
    "# model = LogisticRegression(random_state=42)\n",
    "\n",
    "# # Step 3: Model Training\n",
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# # Step 4: Model Evaluation\n",
    "# # Predict on the test set\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(Y_test, Y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# # Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # Classification Report\n",
    "# class_report = classification_report(Y_test, Y_pred)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report)\n",
    "\n",
    "# # Step 5: Model Optimization\n",
    "# # We can perform hyperparameter tuning using GridSearchCV\n",
    "# param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "# grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# # Step 6: Final Model Evaluation\n",
    "# # Use the best model from GridSearchCV\n",
    "# final_model = grid_search.best_estimator_\n",
    "# Y_pred_final = final_model.predict(X_test)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy_final = accuracy_score(Y_test, Y_pred_final)\n",
    "# print(f\"Final Model Accuracy: {accuracy_final:.2f}\")\n",
    "\n",
    "# # Confusion Matrix for the final model\n",
    "# conf_matrix_final = confusion_matrix(Y_test, Y_pred_final)\n",
    "# print(\"Confusion Matrix for Final Model:\")\n",
    "# print(conf_matrix_final)\n",
    "\n",
    "# # Classification Report for the final model\n",
    "# class_report_final = classification_report(Y_test, Y_pred_final)\n",
    "# print(\"Classification Report for Final Model:\")\n",
    "# print(class_report_final)\n",
    "\n",
    "# # Step 7: Conclusion\n",
    "# # Analyze the results and draw conclusions\n",
    "# print(\"Conclusion:\")\n",
    "# print(\"The initial Logistic Regression model achieved an accuracy of\", accuracy)\n",
    "# print(\"After hyperparameter tuning, the final model achieved an accuracy of\", accuracy_final)\n",
    "\n",
    "# # Plot the decision boundary for the final model\n",
    "# xx, yy = np.meshgrid(np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100),\n",
    "#                      np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 100))\n",
    "# Z = final_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "# plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test, cmap=plt.cm.RdBu)\n",
    "# plt.xlabel(\"Feature 1\")\n",
    "# plt.ylabel(\"Feature 2\")\n",
    "# plt.title(\"Decision Boundary for Final Model\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
